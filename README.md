# ğŸ–Šï¸ MNIST Digit Recognition â€“ Neural Network from Scratch

This project implements a **handwritten digit recognition system** using the MNIST dataset, built entirely from scratch with **NumPy** and **pandas**.  

The model uses **forward propagation, ReLU activation, softmax, backpropagation, and gradient descent** to classify digits (0â€“9).  
I achieved **86.4% accuracy**.

---

## ğŸ“Œ Overview
- Implemented a 2-layer neural network using only **NumPy**.
- Built functions for:
  - Forward propagation
  - Backpropagation
  - Gradient Descent
  - One-hot encoding
  - Accuracy evaluation
- Achieved ~86.4% accuracy after training.

---

## ğŸ“Š Results
- **Training Accuracy**: ~86.4%  

---

## ğŸ™ Acknowledgments
This project was inspired by the YouTube tutorial:  
**[Building a Neural Network from Scratch (NumPy & Math Only)](https://youtu.be/w8yWXqWQYmU?si=N04d287lyjWtS4Rk)**  

I followed the tutorial to understand core neural network concepts, then adapted and extended it with training experiments to reach 86.4% accuracy.

---

## ğŸ’¡ Learnings
- Understood how neural networks work at a mathematical level.  
- Implemented backpropagation manually using derivatives.  
- Improved coding and debugging skills in **NumPy**.  

