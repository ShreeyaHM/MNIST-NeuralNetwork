# 🖊️ MNIST Digit Recognition – Neural Network from Scratch

This project implements a **handwritten digit recognition system** using the MNIST dataset, built entirely from scratch with **NumPy** and **pandas**.  

The model uses **forward propagation, ReLU activation, softmax, backpropagation, and gradient descent** to classify digits (0–9).  
I achieved **86.4% accuracy**.

---

## 📌 Overview
- Implemented a 2-layer neural network using only **NumPy**.
- Built functions for:
  - Forward propagation
  - Backpropagation
  - Gradient Descent
  - One-hot encoding
  - Accuracy evaluation
- Achieved ~86.4% accuracy after training.

---

## 📊 Results
- **Training Accuracy**: ~86.4%  

---

## 🙏 Acknowledgments
This project was inspired by the YouTube tutorial:  
**[Building a Neural Network from Scratch (NumPy & Math Only)](https://youtu.be/w8yWXqWQYmU?si=N04d287lyjWtS4Rk)**  

I followed the tutorial to understand core neural network concepts, then adapted and extended it with training experiments to reach 86.4% accuracy.

---

## 💡 Learnings
- Understood how neural networks work at a mathematical level.  
- Implemented backpropagation manually using derivatives.  
- Improved coding and debugging skills in **NumPy**.  

